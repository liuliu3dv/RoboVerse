defaults:
  - ../default

task_name: "isaacgym_envs:Cartpole"
robot_name: "cartpole"

algo: "ppo"

observation_space:
  shape: [4]  # [cart_pos, cart_vel, pole_angle, pole_angular_vel]
observation_shape: [4]

ppo:
  action_num: 1  # Single action for cart force
  multi_gpu: ${experiment.multi_gpu}
  num_actors: ${environment.num_envs}
  e_clip: 0.2
  clip_value: True
  entropy_coef: 0.01
  critic_coef: 1.0
  bounds_loss_coef: 0.0
  gamma: 0.99
  tau: 0.95
  truncate_grads: True
  grad_norm: 1.0
  value_bootstrap: True
  normalize_advantage: True
  normalize_input: True
  normalize_value: True
  reward_scale_value: 1.0
  clip_value_loss: True
  horizon_length: 128
  minibatch_size: 64
  mini_epochs: 8
  learning_rate: 3e-4
  lr_schedule: "adaptive"
  max_agent_steps: 500000  # Smaller for Cartpole as it's simpler
  kl_threshold: 0.016
  save_frequency: 25
  save_best_after: 25
  seq_len: 4

  network:
    mlp:
      units: [64, 64]  # Smaller network for simple task
    separate_value_mlp: True
